{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896354ae",
   "metadata": {},
   "source": [
    "# Машинное обучение для текстов. Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173f875",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5900a83",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построить модель со значением метрики качества *F1* не меньше 0.75. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db6a2a",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05402b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import re \n",
    "import datetime\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import zlib\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, \\\n",
    "                            recall_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_magic = 1024\n",
    "F1_target_score = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c2e56",
   "metadata": {},
   "source": [
    "Выполним загрузку пакета nltk для символьной и статистической обработки естественного языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f45c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk_stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ae1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768bc29",
   "metadata": {},
   "source": [
    "Расширим список стоп-слов английского языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ffdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(['i\\'m', 'hi', '\\'m', '\\'t', '\\'s', '\\'', 'u', 'ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_MAGIC = 1024\n",
    "F1_TARGET_SCORE = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da49ad",
   "metadata": {},
   "source": [
    "Выполним загрузку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13546f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17bc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc774fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'toxic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb11d8",
   "metadata": {},
   "source": [
    "Данные представлены таблицей с двумя столбцами. Столбец text содержит текст комментария, а toxic — целевой признак, всего 159571 комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51316f34",
   "metadata": {},
   "source": [
    "Дубликаты в данных отсутствуют"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля токсичных коментариев: {0:.1%}'.format(data['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee36d50",
   "metadata": {},
   "source": [
    "Посмотрим на примеры отдельных комментариев отнесенных к категории токсчиных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[target] == 1].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4cb3b",
   "metadata": {},
   "source": [
    "Во-первых следует обратить внимание на то, что некоторые комментарии написаны в UPPERCASE. Чтобы не потерять эту информацию при последующей обработке текста, добавим новый признак к набору данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_upper'] = data['text'].str.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b235416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля токсичных коментариев среди текстов в UPPERCASE: {0:.1%}'.format(\n",
    "    data[data['is_upper'] == 1]['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf75fcd",
   "metadata": {},
   "source": [
    "Как видим, доля токсичных комментариев среди текстов в UPPERCASE существенно выше чем во всем наборе данных, это связано с тем, что токсичные комментарии пишут с сильным эмоциональным окрасом. Соответственно указанный признак целесообразно использовать при обучении модели.\n",
    "\n",
    "Далее проведем очистку текстов от знаков препинания, токенизацию и последующую лемматизацию исходного текста. Лемматизированный текст в дальнейшем будет использоваться для построения TF-IDF матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5576bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    eng = re.sub(r'[^A-Za-z \\']', ' ', text) \n",
    "    \n",
    "    text_tokens = tokenizer.tokenize(eng)\n",
    "\n",
    "    return \" \".join([word for word in text_tokens if not word in stopwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459dd0cc",
   "metadata": {},
   "source": [
    "Создадим функцию замены тегов nltk на теги wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dadfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagger(nltk_tag): \n",
    "    if nltk_tag.startswith('J'): \n",
    "        return wordnet.ADJ \n",
    "    elif nltk_tag.startswith('V'): \n",
    "        return wordnet.VERB \n",
    "    elif nltk_tag.startswith('N'): \n",
    "        return wordnet.NOUN \n",
    "    elif nltk_tag.startswith('R'): \n",
    "        return wordnet.ADV \n",
    "    else:           \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaed6e4",
   "metadata": {},
   "source": [
    "Создадим функцию для лемматизации с уточненными частями речи. Будем использовать WordNetLemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_lemmatize(text):\n",
    "    \n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    \n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "    \n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    \n",
    "    for word, tag in wordnet_tagged: \n",
    "        if tag is None: \n",
    "            lemmatized_sentence.append(word) \n",
    "        else:         \n",
    "            lemmatized_sentence.append(wnl.lemmatize(word, tag)) \n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "    \n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6307444",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clear_text'] = data['text'].str.lower().apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = data['clear_text'].apply(pos_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c184f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['lemm_text'].str.count(r'[ ]') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7740786",
   "metadata": {},
   "source": [
    "Кроме того, дополним обучающие признаки синтетическим признаком zip_ratio - соотношением объема сжатого лемматизированного текста к исходному объему текста. В основе генерации указанного признака предположение о том, что для токсичных комментариев относительно нетоксичных комментариев характерна другая информативность (возможно, чаще используются повторения слов и фраз целиком, более частое употребление стоп-слов), соответственно по степени сжатия указанные тексты также будут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_compressed_ratio(text):\n",
    "    text_rep = text.replace(' ', '')\n",
    "    text_len = len(text)\n",
    "\n",
    "    if (text_len > 0):\n",
    "        compressed = zlib.compress(bytes(text_rep, 'utf-8'))\n",
    "        return len(compressed) \n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['src_len'] = data['text'].str.len()\n",
    "data['lemm_len'] = data['lemm_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zip_len'] = data['lemm_text'].apply(calc_compressed_ratio)\n",
    "data['zip_ratio'] = data[['zip_len','lemm_len']].min(axis=1) / data['src_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276d1dd",
   "metadata": {},
   "source": [
    "Рассмотрим особенности и распределение обучающих признаков по целевым классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_column_category(column, title, df):\n",
    "    \"\"\"\n",
    "    функция отображения сводной информации о категориальном признаке:\n",
    "    выводит в текстовом виде униклаьные значения признака и график (гистограмму) \n",
    "    распределения по категориям: действующие и ушедшие клиенты\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Признак', column, ':\\n')\n",
    "    print('Уникальные значения (процент):')\n",
    "    print(df[column].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
    "    \n",
    "    print(\"\\nДоля по целевому признаку (токсичные/все комментарии):\")\n",
    "    print((\n",
    "            df.query('toxic == 1')[column].value_counts() / \n",
    "            df[column].value_counts()\n",
    "        ).mul(100).round(1).astype(str) + '%'\n",
    "    )\n",
    "        \n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x = column,  \n",
    "        color = 'toxic',\n",
    "        color_discrete_map={\n",
    "                0: 'Green', 1: 'Red'\n",
    "            },\n",
    "        opacity = 0.7,\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=title, yaxis_title='Число комментариев')\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fde4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_column_numeric(column, title, df):\n",
    "    \"\"\"\n",
    "    функция отображения сводной информации о числовом признаке:\n",
    "    выводит в текстовом виде основные параметры распределения значений признака и график\n",
    "    (гистограмму и \"ящик с усами\")распределения по категориям:\n",
    "    действующие и ушедшие клиенты\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Признак', column, ':')\n",
    "    \n",
    "    print(df[column].describe())\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x = column, \n",
    "        marginal = 'box', \n",
    "        color = \"toxic\",\n",
    "        color_discrete_map={\n",
    "                0: 'Green', 1: 'Red'\n",
    "            },\n",
    "        opacity = 0.7,\n",
    "        title = title\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=title, yaxis_title='Число комментариев')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33feff80",
   "metadata": {},
   "source": [
    "Рассмотрим тексты, в которых после лемматизации осталось только 1 слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('word_count == 1').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов с 1 словом после лемматизации относительно всех данных: {0:.1%}'.format(\n",
    "    data.query('word_count == 1').shape[0] / data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88135e",
   "metadata": {},
   "source": [
    "Среди указанных текстов есть как ошибочные (например, содержащие только дату или IP-адрес), так и пустые (например, \"No, it doesn´t\" - в силу особенностей английского языка предложения, состоящие только из стоп-слов могут быть значимыми в общем контексте - например, как ответ на предыдущий комментарий).\n",
    "\n",
    "Доля таких текстов - менее 1%. Учитывая то, что в дальшнейшем можно встроить в модель дополнительные проверки (например, проверка по словарю ненормативной лексики), то рассматривать тексты, состоящие из 1 слова (после лемматизации) в целом нецелесообразно, исключим их из рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a625e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('word_count > 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8ce62",
   "metadata": {},
   "source": [
    "Рассмотрим распределение исходных текстов по длине текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('src_len', 'Длина текста', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0b534",
   "metadata": {},
   "source": [
    "Посмотрим на \"выбросы\" по длине текста, в качестве возможной границы отсечения возьмем Q3+3*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439583f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_3iqr = data['src_len'].quantile(0.75) + 3 * (\n",
    "    data['src_len'].quantile(0.75) - data['src_len'].quantile(0.25))\n",
    "q3_3iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5766e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['src_len'] > q3_3iqr].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff55dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов длины более {0} символов относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    data.query('src_len > @q3_3iqr').shape[0] / data.shape[0]))\n",
    "\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    data[data['src_len'] > q3_3iqr]['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc75686",
   "metadata": {},
   "source": [
    "Доля токсичных комментариев среди отобранных \"длинных\" текстов немного меньше их доли в общем объеме данных. В целом объем \"длинных\" текстов составляет ~4.4% исходной выборки.\n",
    "\n",
    "У нас недостаточно сведений о деятельности Интернет-магазина «Викишоп», но с большой долей уверенности можно предположить, что разумное ограничение на длину комментария/описания товара, оставляемого пользователем, вполне допустимо (в целом, это нормальная практика, когда при вводе текста пользователь ограничен в количестве вводимых символов/слов). Исключим указанные \"длинные\" тексты из дальнейшего рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a706544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('src_len <= @q3_3iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('src_len', 'Длина текста', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2287058",
   "metadata": {},
   "source": [
    "Теперь форма распределения текстов по длине близка к распределению Пуассона."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3e6f0",
   "metadata": {},
   "source": [
    "Рассмотрим распределение исходных текстов по длине лемматизированного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('lemm_len', 'Длина лемматизированного текста', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb7bfb",
   "metadata": {},
   "source": [
    "Посмотрим на \"выбросы\" по длине текста после лемматизации, в качестве возможной границы отсечения возьмем Q3+3*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da974181",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_3iqr = data['lemm_len'].quantile(0.75) + 3 * (\n",
    "    data['lemm_len'].quantile(0.75) - data['lemm_len'].quantile(0.25))\n",
    "q3_3iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['lemm_len'] > q3_3iqr].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82068f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов длины более {0} символов после лемматизации относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    data.query('lemm_len > @q3_3iqr').shape[0] / data.shape[0]))\n",
    "\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    data[data['lemm_len'] > q3_3iqr]['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d93731",
   "metadata": {},
   "source": [
    "Доля токсичных комментариев среди отобранных \"длинных\" текстов немного меньше их доли в общем объеме данных. В целом объем \"длинных\" текстов составляет ~1.3% исходной выборки.\n",
    "\n",
    "Учитывая то, что мы ввели ограничение на общую длину оставляемого комментария, цеелесообразно также рассмотреть и длины текстов после лемматизации (или их соотношение с исходной длиной). Наверно здесь требуются более глубокие лингвистические исследования или статистические сведения об особенностях текстов на английском языке, но было бы разумно предположить, что \"обычные\" комментарии (оставляемые пользователями) с точки зрения длины лемматизированных текстов отличаются, например, от сгенерированных ботами или выдержками из специальной литературы. В рамках построения настоящей модели мы исключим указанные \"длинные\" лемматизированные тексты из дальнейшего рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ea391",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('lemm_len <= @q3_3iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('lemm_len', 'Длина лемматизированного текста', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4dafc7",
   "metadata": {},
   "source": [
    "Рассмотрим распределение исходных текстов по соотношению объема сжатого текста к исходному объему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric('zip_ratio', 'Доля сжатия', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов с коэффициентом сжатия менее 0.2 относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    data.query('zip_ratio < 0.2').shape[0] / data.shape[0])\n",
    "     )\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    data.query('zip_ratio < 0.2')['toxic'].mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('zip_ratio < 0.2').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375fdf32",
   "metadata": {},
   "source": [
    "Среди текстов с высоким коэффициентом сжатия доля токсичных существенно выше, чем в среднем по набору данных. При этом указанные тексты вполне могут быть написаны человеком. Их целесообразно оставить для обучения (этот признак может оказаться значимым).\n",
    "\n",
    "Посмотрим на \"выбросы\" в районе 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Доля текстов с коэффициентом сжатия равным 1 относительно всех данных: {1:.1%}'.format(int(q3_3iqr),\n",
    "    data.query('zip_ratio == 1').shape[0] / data.shape[0]))\n",
    "\n",
    "print('Доля токсичных коментариев в указанных текстах: {0:.1%}'.format(\n",
    "    data.query('zip_ratio == 1')['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('zip_ratio == 1').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d7be17",
   "metadata": {},
   "source": [
    "Указанные тексты в основном похожи на служебные сообщения (в том числе, перенаправления на другие комментарии/статьи). В них доля токсичных совпадает со средней по набору данных.\n",
    "\n",
    "Указанные тексты исключим из дальнейшего рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('zip_ratio < 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434aa435",
   "metadata": {},
   "source": [
    "Рассмотрим долю токсичных комментариев в UPPERCASE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb1260",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_category('is_upper', 'Текст в UPPERCASE', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbadc09",
   "metadata": {},
   "source": [
    "Доля токсичных комментариев в UPPERCASE намного выше, чем в среднем по набору данных. Указанный признак целесообразно использовать при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('После удаления выбросов в наборе данных осталось: {0} записей'.format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3751c3",
   "metadata": {},
   "source": [
    "Выделим в исходном наборе данных обучающую и тестовую выборки со стратификацией по целевому признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e25316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    data, test_size=0.15, random_state=random_magic, stratify=data[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c67e2",
   "metadata": {},
   "source": [
    "Наиболее часто употребляемые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_all_class(df_data, target_value):\n",
    "    text = \" \"\n",
    "    category = df_data[df_data[target] == target_value]\n",
    "    for idx, row in tqdm(category.iterrows(), total=category.shape[0]):\n",
    "        text += row['lemm_text'] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678832df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(df_data, target_value, figsize=(7, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    category = get_text_all_class(df_data, target_value)\n",
    "    wordcloud = WordCloud(max_font_size=40).generate(category)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ef5d3",
   "metadata": {},
   "source": [
    "Отобразим в виде облака слов наиболее часто встречаемые слова в каждом из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9148ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(df_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922557cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(df_train, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83205613",
   "metadata": {},
   "source": [
    "Следует отметить, что для класса токсичных комментариев ожидаемо наиболее часто употребляемыми являются нецензурные слова. Вместе с тем, отдельные общеупотребительные слова (например, think, one, page, article, make) являются частыми в обоих классах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae8d6a",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "Исходные данные представлены в виде одной таблицы с двумя признаками:\n",
    "\n",
    "* текст (комментарий)\n",
    "* признак токсичности (целевой признак)\n",
    "В таблице содержится 159571 запись с размеченными комментариями. Дубликатов в исходном наборе данных нет. Доля токсичных комментариев в общем объеме данных - 10%. При обучении модели следует учитывать то, что целевые классы несбалансированы.\n",
    "\n",
    "По условиям задачи моделирования требуется обучить модель, позволяющую классифицировать текст по признаку токсичности. Указанная модель предполагается к использованию Интернет-магазином «Викишоп» при оценке описаний товаров, оставляемых пользователями. Модель должна искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Метрикой качества является F1, целевым значением - 0.75. При этом следует обращать внимание на значение метрик полнота и точность. С точки зрения бизнеса интерпретировать эти метрики можно следующим образом:\n",
    "\n",
    "* полнота (recall) тем выше, чем меньше ложноотрицательных прогнозов дает модель - т.е. меньше количество пропущенных \"токсичных\" комментариев - указанная метрика содержит \"репутационные\" риски и издержки магазина (их сложно перевести непосредственно в денежное выражение, это скорее репутационные потери от наличия на сайте токсичных (в том числе, возможно, содержащих нецензурную лексику) комментариев\n",
    "* точность (precision) тем выше, чем меньше ложноположительных прогнозов - т.е. ошибочно отправленных на модерацию нетоксчиных комментариев - указанная метрика имеет непосредственное денежное выражение, это стоимость модерации одного комментария (у.е./час). О бизнесе Интернет-магазина «Викишоп» дополнительных данных не представлено, но с высокой степенью вероятности следует считать метрику полноты более значимой в денежном выражении относительно точности (репутационные риски обычно намного выше чем стоимость оплаты труда оператора/модератора).\n",
    "\n",
    "На этапе подготовки данных обучающие признаки дополнены несколькими синтетическими признаками, в частности zip_ratio - соотношением объема сжатого лемматизированного текста к исходному объему текста. В основе генерации указанного признака предположение о том, что для токсичных комментариев относительно нетоксичных комментариев характерна другая информативность (возможно, чаще используются повторения слов и фраз целиком, более частое употребление стоп-слов), соответственно по степени сжатия указанные тексты также будут отличаться.\n",
    "\n",
    "На этапе анализа проведена оценка распределения значений отдельных признаков по целевым классам. Устранены отдельные выбросы, в том числе по длине представленных текстов, на основе предположения об имеющихся на сайте Интернет-магазина «Викишоп» разумных ограничениях на длину комментария/описания товара, оставляемого пользователем.\n",
    "\n",
    "Данные подготовлены для последующего обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17e7b3",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6f0c5",
   "metadata": {},
   "source": [
    "Рассчитаем частоты слов обучающей выборки и на их основе составим матрицы TF-IDF для корпуса слов обучающей и тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_train['lemm_text']\n",
    "\n",
    "count_tf_idf = TfidfVectorizer() \n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus) \n",
    "\n",
    "tf_idf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_test['lemm_text']\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(corpus) \n",
    "\n",
    "tf_idf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48506f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_Y = df_train[target]\n",
    "df_test_Y = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe17348",
   "metadata": {},
   "source": [
    "Дополним сформированные TF-IDF матрицы значениями дополнительных обучающих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef99ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X = tf_idf_train\n",
    "df_train_X = hstack((df_train_X, np.array(df_train['is_upper'])[:,None]))\n",
    "df_train_X = hstack((df_train_X, np.array(df_train['zip_ratio'])[:,None]))\n",
    "df_train_X = hstack((df_train_X, np.array(df_train['lemm_len'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_X = tf_idf_test\n",
    "df_test_X = hstack((df_test_X, np.array(df_test['is_upper'])[:,None]))\n",
    "df_test_X = hstack((df_test_X, np.array(df_test['zip_ratio'])[:,None]))\n",
    "df_test_X = hstack((df_test_X, np.array(df_test['lemm_len'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_roc_auc_plot(df_roc_auc, roc_auc_val, color):\n",
    "    \"\"\"\n",
    "    функция печати графика ROC-кривой\n",
    "    df_roc_auc - dataframe исходных данных для построения графика ROC-кривой(значения TPR, FPR и пороговые отсечки)\n",
    "    roc_auc_val - значение метрики ROC-AUC\n",
    "    color - цвет отображения\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.area(\n",
    "        df_roc_auc,\n",
    "        x='fpr', y='tpr',\n",
    "        title=f'ROC-кривая (AUC={roc_auc_val:.4f})',\n",
    "        width=900, \n",
    "        height=500,\n",
    "        color='color',\n",
    "        color_discrete_map={\n",
    "                'red': 'Red', 'green': 'Green'\n",
    "            },\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1], \n",
    "            y=[0, 1], \n",
    "            name=\"Случайная модель\",\n",
    "            line=dict(color=color, width=2, dash='dash'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=0.9)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.update_layout(xaxis_title='FPR (доля ложноположительных)', yaxis_title='TPR (доля истинно положительных)')\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(model_fitted, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    функция печати метрик обученной модели\n",
    "    \n",
    "    \"\"\"\n",
    "    predictions = model_fitted.predict(X_test)\n",
    "    \n",
    "    probabilities_valid = model_fitted.predict_proba(X_test)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    f1_val = f1_score(Y_test, predictions)\n",
    "    roc_auc_val = roc_auc_score(Y_test, probabilities_one_valid)\n",
    "    \n",
    "    print(colored(\"\\x1b[1mF1: {0}\\x1b[0m\".format(f1_val), 'red' if f1_val < F1_TARGET_SCORE else 'green'))\n",
    "    print('AUC-ROC:', roc_auc_val)\n",
    "    print('Precision:', precision_score(Y_test, predictions))\n",
    "    print('Recall:', recall_score(Y_test, predictions))\n",
    "    print('Accuracy:', accuracy_score(Y_test, predictions))\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, probabilities_one_valid) \n",
    "\n",
    "    df_roc_auc = pd.DataFrame()\n",
    "    df_roc_auc['fpr'] = fpr\n",
    "    df_roc_auc['tpr'] = tpr\n",
    "    df_roc_auc['thresholds'] = thresholds\n",
    "    df_roc_auc['color'] = 'red'\n",
    "        \n",
    "    if f1_val >= F1_TARGET_SCORE:\n",
    "        df_roc_auc['color'] = 'green'\n",
    "        print_roc_auc_plot(df_roc_auc, roc_auc_val, 'green')\n",
    "    else:\n",
    "        print_roc_auc_plot(df_roc_auc, roc_auc_val, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_df(model_fitted, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    функция формирования датафрейма со значениями метрик precision, recall и f1 в диапазоне порогов\n",
    "    \n",
    "    \"\"\"\n",
    "    probabilities_valid = model_fitted.predict_proba(X_test)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    scores = []\n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        predicted_valid = probabilities_one_valid > threshold\n",
    "        precision = precision_score(Y_test, predicted_valid)\n",
    "        recall = recall_score(Y_test, predicted_valid)\n",
    "        f1 = f1_score(Y_test, predicted_valid)\n",
    "\n",
    "        scores.append([threshold, precision, recall, f1])\n",
    "        \n",
    "    df_scores = pd.DataFrame(scores, columns=['threshold', 'precision', 'recall', 'f1'])\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_proba(df_scores):\n",
    "    \n",
    "    \"\"\"\n",
    "    функция вывода графика метрик precision, recall и f1\n",
    "\n",
    "    \"\"\"\n",
    "    fig = px.area(\n",
    "        df_scores,\n",
    "        x='threshold', \n",
    "        y='f1',\n",
    "        width=900, \n",
    "        height=500,\n",
    "        color_discrete_map={\n",
    "                'red': 'Red', 'green': 'Green'\n",
    "            },\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_scores['threshold'], \n",
    "            y=df_scores['precision'], \n",
    "            name=\"Точность (precision)\",\n",
    "            line=dict(color='red', width=2),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_scores['threshold'], \n",
    "            y=df_scores['recall'], \n",
    "            name=\"Полнота (recall)\",\n",
    "            line=dict(color='blue', width=2),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0.1,0.9],\n",
    "            y=[F1_TARGET_SCORE, F1_TARGET_SCORE], \n",
    "            name=\"Целевое значение<br>метрики F1\",\n",
    "            line=dict(color='magenta', width=3),\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=0.9)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            #range=[0.1, 0.9],\n",
    "\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[0.6, 0.95],\n",
    "        ),\n",
    "        \n",
    "        \n",
    "        xaxis_title='Порог', \n",
    "        yaxis_title='Метрика'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(6, random_state=RANDOM_MAGIC, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365d9f5",
   "metadata": {},
   "source": [
    "Проведем обучение и последующий анализ нескольких моделей на подготовленных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9c932",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be58b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=random_magic, max_iter=5000, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "param_grid_lr = {\n",
    "    'model__C': [100, 10, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03144c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_grid_lr\n",
    "model = model_lr\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    Pipeline([('model', model)]), \n",
    "    param_grid=params, \n",
    "    cv=cv, \n",
    "    scoring=scoring\n",
    ")    \n",
    "\n",
    "grid_search.fit(df_train_X, df_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d629f",
   "metadata": {},
   "source": [
    "Выведем график кривой ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46874744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(grid_search, df_test_X, df_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164c112",
   "metadata": {},
   "source": [
    "Выведем график зависимости метрик от используемых порогов отнесения к целевым классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_proba_df(grid_search, df_test_X, df_test_Y)\n",
    "print_proba(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f64d09",
   "metadata": {},
   "source": [
    "На графике видно, что целевое значение метрики F1 достигается в достаточно широком диапазоне порогов - примерно в интервале от 0.49 до 0.59. Вместе с тем, одновременно необходимо оценивать значения метрик полноты и точности. Учитывая то, что ранее мы определили метрику полноты более значимой с точки зрения ее \"стоимости\" в бизнесе, к приемлемым значениям порогов следует отнести более узкий интервал вокруг точки пересечения метрик - (0.6, 0.7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.loc[(df_scores[\"threshold\"] >= 0.6) & (df_scores[\"threshold\"] <= 0.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2b39c",
   "metadata": {},
   "source": [
    "**LinearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = LinearSVC(random_state=random_magic, max_iter=5000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CalibratedClassifierCV(model_svc, cv = cv) \n",
    "clf.fit(df_train_X, df_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(clf, df_test_X, df_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66edf0",
   "metadata": {},
   "source": [
    "Выведем график зависимости метрик от используемых порогов отнесения к целевым классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_proba_df(clf, df_test_X, df_test_Y)\n",
    "print_proba(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93a644",
   "metadata": {},
   "source": [
    "На графике видно, что целевое значение метрики F1 также достигается в достаточно широком диапазоне порогов - примерно в интервале от 0.17 до 0.56. К приемлемым значениям порогов следует отнести более узкий интервал вокруг точки пересечения метрик - (0.23, 0.33)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.loc[(df_scores[\"threshold\"] >= 0.22) & (df_scores[\"threshold\"] <= 0.32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff056cf",
   "metadata": {},
   "source": [
    "**CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc73a5",
   "metadata": {},
   "source": [
    "Перейдем к рассмотрению модели, которая учитывает не только частоты слов в тексте, но и частоты различных синтаксических N-грамм (последовательностей лемматизированных слов).\n",
    "\n",
    "Дополнительно разделим обучающую выборку на обучающую и валидационную (доля валидационной примерно соответствует доле тестовой выборки для финальной проверки модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8dde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_train,\n",
    "                                                test_size=0.15, \n",
    "                                                stratify=df_train['toxic'], \n",
    "                                                shuffle=True, random_state=random_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['is_upper', 'zip_ratio', 'lemm_len', 'lemm_text']\n",
    "\n",
    "cat_features = ['is_upper']\n",
    "\n",
    "text_features = ['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ec20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    verbose=50,\n",
    "    eval_metric='AUC',\n",
    "    task_type=\"CPU\",\n",
    "    iterations=1000,\n",
    "    learning_rate=0.2,      \n",
    "    \n",
    "    text_processing = {\n",
    "        \"tokenizers\" : [{\n",
    "            \"tokenizer_id\" : \"Space\",\n",
    "            \"separator_type\" : \"ByDelimiter\",\n",
    "            \"delimiter\" : \" \"\n",
    "        }],\n",
    "\n",
    "        \"dictionaries\" : [{\n",
    "            \"dictionary_id\" : \"BiGram\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"2\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Trigram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"3\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Fourgram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"4\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Fivegram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"5\"\n",
    "        },{\n",
    "            \"dictionary_id\" : \"Sixgram\",\n",
    "            \"max_dictionary_size\" : \"150000\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"occurrence_lower_bound\" : \"1\",\n",
    "            \"gram_order\" : \"6\"\n",
    "        }\n",
    "        ],\n",
    "\n",
    "        \"feature_processing\" : {\n",
    "            \"default\" : [\n",
    "                    {\n",
    "                    \"dictionaries_names\" : [\"BiGram\", \"Trigram\", \"Fourgram\", \"Fivegram\", \"Sixgram\"],\n",
    "                    \"feature_calcers\" : [\"BoW\"],\n",
    "                    \"tokenizers_names\" : [\"Space\"]\n",
    "                },\n",
    "                    {\n",
    "                \"dictionaries_names\" : [\"BiGram\", \"Trigram\", \"Fourgram\", \"Fivegram\", \"Sixgram\"],\n",
    "                \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },{\n",
    "                \"dictionaries_names\" : [ \"BiGram\", \"Trigram\", \"Fourgram\", \"Fivegram\", \"Sixgram\"],\n",
    "                \"feature_calcers\" : [\"BM25\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35840eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train[feature_names], train[target],\n",
    "    eval_set=(valid[feature_names], valid[target]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_X = df_test[feature_names]\n",
    "df_test_Y = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(model, df_test_X, df_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91745fd3",
   "metadata": {},
   "source": [
    "Выведем график зависимости метрик от используемых порогов отнесения к целевым классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = get_proba_df(model, df_test_X, df_test_Y)\n",
    "print_proba(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79faeb0",
   "metadata": {},
   "source": [
    "В отличие от рассмотренных выше моделей на графике видно, что целевое значение метрики F1 также достигается не только в более широком диапазоне порогов - примерно в интервале от 0.13 до 0.76 - но и само значение метрики F1 существенно выше. К приемлемым значениям порогов следует отнести более узкий интервал вокруг точки пересечения метрик - (0.24, 0.40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ad871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.loc[(df_scores[\"threshold\"] >= 0.27) & (df_scores[\"threshold\"] <= 0.40)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a99d38",
   "metadata": {},
   "source": [
    "## Анализ наилучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04afb06f",
   "metadata": {},
   "source": [
    "Проведем анализ результатов, полученных при использовании модели CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7c75f",
   "metadata": {},
   "source": [
    "Проведём оценку значимости обучающих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importance(arr_importance, column_names):\n",
    "    \"\"\"\n",
    "    функция печати графика значимости обучающих признаков\n",
    "    \n",
    "    \"\"\"\n",
    "    rel_feature_imp = np.abs(100 * (arr_importance / max(arr_importance)))\n",
    "    \n",
    "    rel_feature_df = pd.DataFrame(\n",
    "        {\n",
    "            'features' : list(column_names),\n",
    "            'rel_importance' : rel_feature_imp\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rel_feature_df = rel_feature_df.sort_values('rel_importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    ax = sns.barplot(\n",
    "        x = 'rel_importance', \n",
    "        y = 'features',\n",
    "        data = rel_feature_df,\n",
    "        palette = 'Accent_r'\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Относительная значимость', fontsize=25)\n",
    "    plt.ylabel('Признаки', fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = model.get_feature_importance(prettified=True)\n",
    "\n",
    "print_feature_importance(df_importance['Importances'], df_importance['Feature Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d46662",
   "metadata": {},
   "source": [
    "Ожидаемо наиболее значимым признаком оказался лемматизированный текст (и соответственно производное от него векторное представление текста), но вместе с тем и введенные дополнительные признаки имеют ненулевую значимость."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b67a9e",
   "metadata": {},
   "source": [
    "Проведём анализ остатков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_threshold = 0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff24a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_valid = model.predict_proba(df_test_X)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "scores = []\n",
    "\n",
    "predicted_valid = probabilities_one_valid > f1_threshold\n",
    "precision = precision_score(df_test_Y, predicted_valid)\n",
    "recall = recall_score(df_test_Y, predicted_valid)\n",
    "f1 = f1_score(df_test_Y, predicted_valid)\n",
    "\n",
    "scores.append([f1_threshold, precision, recall, f1])\n",
    "        \n",
    "df_scores = pd.DataFrame(scores, columns=['threshold', 'precision', 'recall', 'f1'])\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec401f",
   "metadata": {},
   "source": [
    "Добавим к таргету тестовой выборки предсказанные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_Y_res = pd.DataFrame(df_test_Y.copy())\n",
    "df_test_Y_res['pred'] = pd.DataFrame(np.transpose(predicted_valid.astype(int)), index=df_test_Y_res.index)\n",
    "df_test_Y_res.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407973e",
   "metadata": {},
   "source": [
    "Сфомируем датафреймы с ложноположительными и ложноотрицательными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp = df_test_Y_res.query('pred > toxic')\n",
    "df_fn = df_test_Y_res.query('pred < toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb443f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d627d0",
   "metadata": {},
   "source": [
    "Посмотрим на распределение ложноотрицательных значений по длине исходного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_column_numeric(\n",
    "    'src_len', 'Длина лемматизированного текста', \n",
    "    data.loc[df_fn.index][['toxic', 'src_len', 'lemm_len', 'text', 'lemm_text']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e8030",
   "metadata": {},
   "source": [
    "Распределение в целом повторяет распределение на обучающей выборке, но при этом правая граница межквартильного размаха смещена вправо, т.е. больше \"длинных\" текстов попало в межквартильный интервал ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[df_fn.index].query('src_len < 250').sample(30)[['toxic', 'is_upper', 'src_len', 'text', 'lemm_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca499325",
   "metadata": {},
   "source": [
    "По указанным примерам можно сделать следующие предположения о возможных направлениях улучшения модели:\n",
    "\n",
    "* следует лучше отбирать значения в UPPERCASE (например, считать долю символов в UPPERCASE относительно всего текста)\n",
    "* следует отдельно интерпретировать нецензурные слова с пропусками букв (например, cr@p, f*ing, WTF, Dl2000CK)\n",
    "* возможно следует подключить проверку по словарю/наличию орфографических ошибок (опять-таки размечать долю слов с ошибками относительно всего текста)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[df_fn.index].query('src_len > 400').sample(15)[['toxic', 'is_upper', 'src_len', 'text', 'lemm_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e0590",
   "metadata": {},
   "source": [
    "На примерах \"длинных\" текстов также можно сделать предположение о возможных направлениях улучшения модели:\n",
    "исключать тексты на политическую тематику (например, с упоминанием стран, национальностей, политических партий) либо давать им соответствующую разметку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967531ef",
   "metadata": {},
   "source": [
    "Также посмотрим на примеры ложноположительных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88332a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[df_fp.index].query('src_len < 250').sample(15)[['toxic', 'is_upper', 'src_len', 'text', 'lemm_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f881361",
   "metadata": {},
   "source": [
    "Примеры ложноположительных ответов вместе с тем говорят скорее об ошибках в разметке исходных данных - очевидно наличие комментариев, которые по содержанию скорее следует отнести к токсичным (что модель и сделала):\n",
    "\n",
    "* ILL COME TO YOUR HOUSE ND MAKE U SORE BETWEEN UR LEGS\n",
    "* A JEW? OR NOT A JEW?\n",
    "* JULIE \\n\\nWOW THANKS FOR BLOCKING ME! hateyouevenmore\n",
    "* moved to http://www.freearchive.org/wiki2/index.php/Tape_editing\\nfor safety (the wikipedia idiots don't want to include this page)\n",
    "* NO I HATE IT BECAUSE YOU DELETE EVERYTHING\n",
    "* shut up man! \\n\\nSHUT UP I DID NOT DO ANYTHING Click Here for what I Wrote To You A Few Months Ago.\n",
    "\n",
    "Указанные примеры говорят об имеющихся недостатках в разметке исходных данных, которые целесообразно в последующем устранить (что также должно сказаться на повышении точности модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7deaf3",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "Исследование проводилось в интересах Интернет-магазина «Викишоп», запускающего новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Цель проекта - обучить модель классифицировать комментарии на позитивные и негативные. На исследование предоставлен набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Исходные данные представлены в виде одной таблицы с двумя признаками:\n",
    "\n",
    "* текст (комментарий)\n",
    "* признак токсичности (целевой признак)\n",
    "\n",
    "В таблице содержится порядка 160 тысяч записей с размеченными комментариями. Дубликатов в исходном наборе данных нет. Доля токсичных комментариев в общем объеме данных - 10%. При обучении модели следует учитывать то, что целевые классы несбалансированы.\n",
    "\n",
    "По условиям задачи моделирования требуется обучить модель, позволяющую классифицировать текст по признаку токсичности. Модель должна искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Метрикой качества является F1, целевым значением - 0.75. При этом следует обращать внимание на значение метрик полнота и точность. С точки зрения бизнеса интерпретировать эти метрики можно следующим образом:\n",
    "\n",
    "* полнота (recall) тем выше, чем меньше ложноотрицательных прогнозов дает модель - т.е. меньше количество пропущенных \"токсичных\" комментариев - указанная метрика содержит \"репутационные\" риски и издержки магазина (их сложно перевести непосредственно в денежное выражение, это скорее репутационные потери от наличия на сайте токсичных (в том числе, возможно, содержащих нецензурную лексику) комментариев\n",
    "* точность (precision) тем выше, чем меньше ложноположительных прогнозов - т.е. ошибочно отправленных на модерацию нетоксчиных комментариев - указанная метрика имеет непосредственное денежное выражение, это стоимость модерации одного комментария (у.е./час). О бизнесе Интернет-магазина «Викишоп» дополнительных данных не представлено, но с высокой степенью вероятности следует считать метрику полноты более значимой в денежном выражении относительно точности (репутационные риски обычно намного выше чем стоимость оплаты труда оператора/модератора).\n",
    "\n",
    "На этапе подготовки данных обучающие признаки дополнены несколькими синтетическими признаками.\n",
    "\n",
    "На этапе анализа проведена оценка распределения значений отдельных признаков по целевым классам. Устранены отдельные выбросы, в том числе по длине представленных текстов, на основе предположения об имеющихся на сайте Интернет-магазина «Викишоп» разумных ограничениях на длину комментария/описания товара, оставляемого пользователем.\n",
    "\n",
    "Проведено обучение двух моделей на основе матрицы TF-IDF значимости слов лемматизированного текста (модели линейной регрессии и LinearSVC), а также модели CatBoostClassifier на основе векторного представления различных N-грамм лемматизированного текста.\n",
    "\n",
    "По результатам обучения модели получены следующие результаты:\n",
    "\n",
    "* все модели позволили достичь целевое значение метрики F1\n",
    "* наилучшее значение метрики показала модель CatBoostClassifier - F1 = 0.79, Точность - 0.81, Полнота - 0.77, при пороговом значении отнесения к положительному классу равным 0.38\n",
    "\n",
    "Анализ неверных предсказаний модели позволил определить возможные направления для ее улучшения:\n",
    "\n",
    "* следует лучше отбирать значения в UPPERCASE (например, считать долю символов в UPPERCASE относительно всего текста)\n",
    "* следует отдельно интерпретировать нецензурные слова с пропусками букв (например, cr@p, f*ing, WTF, Dl2000CK)\n",
    "* возможно следует подключить проверку по словарю/наличию орфографических ошибок (опять-таки размечать долю слов с ошибками относительно всего текста)\n",
    "* исключать тексты на политическую тематику (например, с упоминанием стран, национальностей, политических партий) либо давать им соответствующую разметку\n",
    "\n",
    "Кроме того, выборочная оценка ложноположительных ответов говорит скорее об ошибках в разметке исходных данных - очевидно наличие комментариев, которые по содержанию скорее следует отнести к токсичным (что модель и сделала). Указанные недостатки в разметке исходных данных целесообразно в последующем устранить для повышении точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7dbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1883,
    "start_time": "2022-06-15T04:43:29.384Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-15T04:43:31.269Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-15T05:09:43.919Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-16T02:20:16.065Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
